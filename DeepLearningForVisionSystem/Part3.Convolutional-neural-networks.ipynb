{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classifying images using MLP\n",
    "- Working with the Cnn architecture to classify images\n",
    "- Understanding convolution on color images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The MLP, CNNs are same to learns network(optimizes params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Architecture\n",
    "- Cnns have different structures \n",
    "\n",
    "> Weigths and biases\n",
    "- Both Cnn and MLP are have weights and biases that are initially randomly generated\n",
    "- theire values are learned by the networks\n",
    "---\n",
    "- Main difference between them is weight in MLPs are in vector form\n",
    "- CNNs layers, weights take the form of convolutional filters or kernels\n",
    "\n",
    "> Hyperparameters\n",
    "- Same as MLps (error,activation functions, optimizers)\n",
    "- But add some new one that specific to CNN\n",
    "\n",
    "> Training \n",
    "- Both networks learn the same way\n",
    "- First - forward pass to get prediction\n",
    "- Second - Compare the prediction with the true label to get loss func\n",
    "- Final - optimize parametes using gradient descent, backpropagate the error to all the weights\n",
    "   - update theire values to minimize the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification using MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/wKtgP/btq4lkHhIlG/KVyKh8w9zNxTxbK2FztDM0/img.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- when we put 2-D imgaes to networks \n",
    "    + we need to do specail something to network understand 2-D images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let see how computer perceive images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/1i9I9/btq4hHwGHu9/Ylt9Aw4dYf9adcy8vP0YD0/img.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since MLPs only take as input 1D vectors with dimensions (1,n)\n",
    "- they cannot take raw 2D image matrix with dimension (x,y)\n",
    "---\n",
    "- To fit the images in the input layer\n",
    "- We first need to ransform our image into large vector with the dimension(1,n)\n",
    "    - that contains all the pixel values in the image **aka image flattening** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE WITH KERAS(FLatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How we flatten an input images in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape = (28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Flatten layers in keras handles this process for us\n",
    "- It takes the 2D image matrix input and converts it into 1D vectors\n",
    "- Note that the Flatten layer must be supplied a param value of input image shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- neural network can have one or more hidden layers \n",
    "- each layers has one or more neurons \n",
    "- i can decided to arbitrarily(임의로) design the networks \n",
    "- and Don't forget to add RElu activation function for each hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(512, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output layer is pretty straightforward\n",
    "---\n",
    "- In classifiaction problems\n",
    "- the number of nodes in outlayer should be equal to the number of classes that you trying to detect\n",
    "---\n",
    "- If we classifying 10 digits (0,1,2,3,4,5,6,7,8,9)\n",
    "- Then we need to add 10 nodes in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation ='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/cT5Qn6/btq4kTXhkzQ/mnJHkFKR7ID65VGZ4m28ck/img.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_13 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape = (28,28)))\n",
    "\n",
    "model.add(Dense(512, activation ='relu'))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawbaks of MLPS for processing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
