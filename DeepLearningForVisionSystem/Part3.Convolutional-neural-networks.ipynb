{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classifying images using MLP\n",
    "- Working with the Cnn architecture to classify images\n",
    "- Understanding convolution on color images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The MLP, CNNs are same to learns network(optimizes params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Architecture\n",
    "- Cnns have different structures \n",
    "\n",
    "> Weigths and biases\n",
    "- Both Cnn and MLP are have weights and biases that are initially randomly generated\n",
    "- theire values are learned by the networks\n",
    "---\n",
    "- Main difference between them is weight in MLPs are in vector form\n",
    "- CNNs layers, weights take the form of convolutional filters or kernels\n",
    "\n",
    "> Hyperparameters\n",
    "- Same as MLps (error,activation functions, optimizers)\n",
    "- But add some new one that specific to CNN\n",
    "\n",
    "> Training \n",
    "- Both networks learn the same way\n",
    "- First - forward pass to get prediction\n",
    "- Second - Compare the prediction with the true label to get loss func\n",
    "- Final - optimize parametes using gradient descent, backpropagate the error to all the weights\n",
    "   - update theire values to minimize the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification using MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/wKtgP/btq4lkHhIlG/KVyKh8w9zNxTxbK2FztDM0/img.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- when we put 2-D imgaes to networks \n",
    "    + we need to do specail something to network understand 2-D images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let see how computer perceive images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/1i9I9/btq4hHwGHu9/Ylt9Aw4dYf9adcy8vP0YD0/img.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since MLPs only take as input 1D vectors with dimensions (1,n)\n",
    "- they cannot take raw 2D image matrix with dimension (x,y)\n",
    "---\n",
    "- To fit the images in the input layer\n",
    "- We first need to ransform our image into large vector with the dimension(1,n)\n",
    "    - that contains all the pixel values in the image **aka image flattening** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE WITH KERAS(FLatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How we flatten an input images in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape = (28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Flatten layers in keras handles this process for us\n",
    "- It takes the 2D image matrix input and converts it into 1D vectors\n",
    "- Note that the Flatten layer must be supplied a param value of input image shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- neural network can have one or more hidden layers \n",
    "- each layers has one or more neurons \n",
    "- i can decided to arbitrarily(임의로) design the networks \n",
    "- and Don't forget to add RElu activation function for each hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(512, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output layer is pretty straightforward\n",
    "---\n",
    "- In classifiaction problems\n",
    "- the number of nodes in outlayer should be equal to the number of classes that you trying to detect\n",
    "---\n",
    "- If we classifying 10 digits (0,1,2,3,4,5,6,7,8,9)\n",
    "- Then we need to add 10 nodes in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation ='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.kakaocdn.net/dn/cT5Qn6/btq4kTXhkzQ/mnJHkFKR7ID65VGZ4m28ck/img.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_13 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape = (28,28)))\n",
    "\n",
    "model.add(Dense(512, activation ='relu'))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawbaks of MLPS for processing images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- two major problems in MLPs that convolution networks are designed to fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Spatial feature loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- flattening a 2d -> 1d vector input results in losing spatial features \n",
    "- then why spatial information is importance?\n",
    "- in feature learning points \n",
    "- when 2d to 1d vector it lose information of shape only vector form \n",
    "- so need alot of image sufficient of image \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected (Dense) Layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP\n",
    "- MLPs are composed of dense layer that are fully connected each other \n",
    "- each neuron has params to train per neuron from the previous layers\n",
    "- when image is larger hideen layers become sooo big \n",
    "- input image vector * 1st hidden layers  ( 1000*1000 * 1000) already soo big "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN\n",
    "- Cnn on the other hand are locally connected layers \n",
    "- node are connected to only small subset of the previous layers' nodes\n",
    "- subset of pixels is connected to each neureon "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cnn architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Many neural networks contain multiple layers that allow each layer to find complex features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cnn how to work?\n",
    "- first layer if convolutions learns basic features(edges and line)\n",
    "- next layer learns features that are little more complex (circles, square and so on)\n",
    "- follow are even more complex feature( parts of face ..)\n",
    "---\n",
    "- mlp cnn what's diffirents?\n",
    "    - use convolution layers instead of fully connected layers for featyre learning part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully connections cons \n",
    "- fully connection layers in mlp learn features and classfiy an image together\n",
    "- fully connection no good at feature extraction\n",
    "- but work really well in classifying the extracted features\n",
    "---\n",
    "- so cnn change mlp feature extracion layers to convolution layers\n",
    "- leave the classifying and extracted features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A closer look at feature extracion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature extraction  \n",
    "    - breaking large images into smaller pices of features and stacking them in to a vector \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cnn don't literally break an image into pieces \n",
    "- Instead Cnn extract meaningful feature that separate this object from other images in the training set\n",
    "- Stack them in an array of feature\n",
    "- After feature extraction is complete\n",
    "- we add fully connected layers to look at the features vecotr\n",
    "    - ex\n",
    "    - first layers look it like 3 , 7 with edges\n",
    "    - second layers look it this have no curve so it is not 7\n",
    "    - so on.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic components of CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### main architecure of Cnn\n",
    "- convolution layers (CONV)\n",
    "- pooling layers (POOL)\n",
    "- Fully connected layers (FC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CONv are for feature learning or extracion\n",
    "- FC is for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- convolution layers is the core building block of convolution neural networks\n",
    "- convolition layres act like feature finder window\n",
    "- slides the image pixel by pixel to extract meaningfull feature that identify objects image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Convolution \n",
    "- in math \n",
    "    - convoltion is operation of two finctions to produce third modified function \n",
    "- in CNN\n",
    "    - firtfunction is input image, second function is convolution filter \n",
    "\n",
    "- the first convolution layers to see how process an image \n",
    "<img src=\"https://blog.kakaocdn.net/dn/bj2DBf/btq4MfmL5mV/h4nLsdtoyY9C1c85dSin2k/img.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- kernel: 3*3 value \n",
    "- Receptive field : area of the images that filter convolves\n",
    "- weight : kernel values \n",
    "    - kernel values is randomly initialized and values are learned by network\n",
    "- feature map, activation map\n",
    "    - convolce image(filter pass image) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### creates the convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, strides=1, padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- convolution layers are the hidden layers \n",
    "- each kernel is considered a neuron\n",
    "- 3*3 kernel means 9 hidden units in this layers \n",
    "- remember kernel size is units \n",
    "- bigger is better but too big iot is too compute\n",
    "- 2*2 ~ 5*5 recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STRIDES AND Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
